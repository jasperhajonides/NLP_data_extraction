{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06677d12",
   "metadata": {},
   "source": [
    "# Pipeline for pay ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4b02fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "# adds folder ../scripts to look for module imports\n",
    "sys.path.append('../scripts')\n",
    "\n",
    "from cleaning import *\n",
    "from preprocessing import *\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a716409",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Select year\n",
    "year = \"2020\"\n",
    "directory = r'../data/raw/annual_reports/{}/'.format(year)\n",
    "\n",
    "# Loop over documents\n",
    "filenames = []\n",
    "company_names = []\n",
    "dfs = pd.DataFrame()\n",
    "for filename in tqdm(os.listdir(directory)[0:80]):\n",
    "    if filename.endswith(\".pdf\"):\n",
    "        path = directory + filename\n",
    "        \n",
    "        # Run pattern patcher for each document\n",
    "        df = create_match_dataframe(path, 'ceo_pay_ratio')\n",
    "        company_info = define_company_dictionary(path)\n",
    "        dfs = dfs.append(df)\n",
    "        \n",
    "        \n",
    "dfs.to_csv(\"../data/processed/training_pay_ratio_2020_check.csv\", index=False)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9dbd1f1",
   "metadata": {},
   "source": [
    "# Identify all matches with a true positive on the same page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "976ac406",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#manually labelled data for 125 documents \n",
    "labelled = pd.read_csv('../data/processed/training_data_pay_ratio_labelled.csv')\n",
    "\n",
    "# identified phrases identified by the spaCy PhraseMatcher for 2019 and 2020\n",
    "df_2020 = pd.read_csv(\"../data/processed/training_pay_ratio_2020.csv\")\n",
    "df_2019 = pd.read_csv(\"../data/processed/training_pay_ratio_2019.csv\")\n",
    "\n",
    "# Combine all identified phrases identified by the spaCy PhraseMatcher\n",
    "training_data = df_2019.append(df_2020,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09dd98db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unilever_Annual_Report_2019.pdf\n",
      "found\n",
      "Taylor_Wimpey_Annual_Report_2019.pdf\n",
      "found\n",
      "Rightmove_Annual_Report_2019.pdf\n",
      "found\n",
      "United_Utilities_Annual_Report_2019.pdf\n",
      "Berkeley_Group_Annual_Report_2019.pdf\n",
      "found\n",
      "Ocado_Annual_Report_2019.pdf\n",
      "found\n",
      "M&G_Annual_Report_2019.pdf\n",
      "found\n",
      "JD_Sports_Annual_Report_2019.pdf\n",
      "Severn_Trent_Annual_Report_2019.pdf\n",
      "British_American_Tobacco_Annual_Report_2019.pdf\n",
      "found\n",
      "AstraZeneca_Annual_Report_2019.pdf\n",
      "found\n",
      "ITV_Annual_Report_2019.pdf\n",
      "found\n",
      "Imperial_Brands_Annual_Report_2019.pdf\n",
      "found\n",
      "BAE_Systems_Annual_Report_2019.pdf\n",
      "found\n",
      "Glencore_Annual_Report_2019.pdf\n",
      "found\n",
      "Smurfit_Kappa_Annual_Report_2019.pdf\n",
      "found\n",
      "Lloyds_Banking_Group_Annual_Report_2019.pdf\n",
      "found\n",
      "Prudential_Annual_Report_2019.pdf\n",
      "found\n",
      "Whitbread_Annual_Report_2019.pdf\n",
      "Next_Annual_Report_2019.pdf\n",
      "found\n",
      "St_James's_Place_Annual_Report_2019.pdf\n",
      "found\n",
      "WPP_Annual_Report_2019.pdf\n",
      "found\n",
      "GSK_Annual_Report_2019.pdf\n",
      "found\n",
      "Informa_Annual_Report_2019.pdf\n",
      "found\n",
      "Standard_Chartered_Annual_Report_2019.pdf\n",
      "found\n",
      "Intertek_Group_Annual_Report_2019.pdf\n",
      "found\n",
      "Barclays_Annual_Report_2019.pdf\n",
      "found\n",
      "RELX_Annual_Report_2019.pdf\n",
      "found\n",
      "Smiths_Groups_Annual_Report_2019.pdf\n",
      "found\n",
      "Network_Rail_Annual_Report_2019.pdf\n",
      "found\n",
      "Phoenix_Group_Holdings_Annual_Report_2019.pdf\n",
      "found\n",
      "Legal&General_Annual_Report_2019.pdf\n",
      "found\n",
      "Persimmon_Annual_Report_2019.pdf\n",
      "found\n",
      "Rio_Tinto_Annual_Report_2019.pdf\n",
      "found\n",
      "Pearson_Annual_Report_2019.pdf\n",
      "found\n",
      "Reckitt_Annual_Report_2019.pdf\n",
      "found\n",
      "Ferguson_Annual_Report_2019.pdf\n",
      "Just_Eat_Annual_Report_2019.pdf\n",
      "found\n",
      "Spirax-Sarco_Annual_Report_2019.pdf\n",
      "found\n",
      "Weir_Group_Annual_Report_2019.pdf\n",
      "found\n",
      "HSBC_Holdings_Annual_Report_2019.pdf\n",
      "found\n",
      "B&M_Annual_Report_2019.pdf\n",
      "Melrose_Industries_Annual_Report_2019.pdf\n",
      "found\n",
      "Rolls-Rocye_Annual_Report_2019.pdf\n",
      "found\n",
      "SSE_Annual_Report_2019.pdf\n",
      "found\n",
      "Vodafone_Annual_Report_2019.pdf\n",
      "found\n",
      "Polymetal_Annual_Report_2019.pdf\n",
      "found\n",
      "Fresnillo_Annual_Report_2019.pdf\n",
      "Mondi_Annual_Report_2019.pdf\n",
      "found\n",
      "Schroeders_Annual_Report_2019.pdf\n",
      "found\n",
      "Aviva_Annual_Report_2019.pdf\n",
      "found\n",
      "BP_Annual_Report_2019.pdf\n",
      "found\n",
      "National_Grid_Annual_Report_2019.pdf\n",
      "found\n",
      "Royal_Mail_Annual_Report_2019.pdf\n",
      "found\n",
      "Tesco_Annual_Report_2019.pdf\n",
      "found\n",
      "Scottish_Mortgage_Investment_Trust_Annual_Report_2019.pdf\n",
      "BT_Group_Annual_Report_2019.pdf\n",
      "found\n",
      "British_Land_Annual_Report_2019.pdf\n",
      "found\n",
      "Rentokil_Initial_Annual_Report_2019.pdf\n",
      "found\n",
      "IHG_Hotels&Resorts_Annual_Report_2019.pdf\n",
      "found\n",
      "Johnson_Matthey_Annual_Report_2019.pdf\n",
      "DS_Smith_Annual_Report_2019.pdf\n",
      "found\n",
      "Sainsburys_Annual_Report_2019.pdf\n",
      "Land_Securities_Annual_Report_2019.pdf\n",
      "found\n",
      "CRH_Annual_Report_2019.pdf\n",
      "found\n",
      "Associated_British_Foods_Annual_Report_2019.pdf\n",
      "found\n",
      "Anglo_American_Annual_Report_2019.pdf (Actual year is 2018)\n",
      "Evraz_Annual_Report_2019.pdf\n",
      "Segro_Annual_Report_2019.pdf\n",
      "found\n",
      "Sage_Annual_Report_2019.pdf\n",
      "found\n",
      "Smith&Nephew_Annual_Report_2019.pdf\n",
      "found\n",
      "Hargreaves_Lansdown_Annual_Report_2019.pdf\n",
      "Experian_Annual_Report_2019.pdf\n",
      "BHP_Annual_Report_2019.pdf\n",
      "found\n",
      "Kingfisher_Annual_Report_2019.pdf\n",
      "found\n",
      "Antofagasta_Annual_Report_2019.pdf\n",
      "Royal_Dutch_Shell_Annual_Report_2019.pdf\n",
      "found\n",
      "Auto_Trader_Annual_Report_2019.pdf\n",
      "found\n",
      "DCC_Annual_Report_2019.pdf\n",
      "found\n",
      "Pershing_Square_Holdings_Annual_Report_2019.pdf\n",
      "IHG_Hotels&Resorts_Annual_Report_2020.pdf\n",
      "found\n",
      "Aggreko_Annual_Report_2020.pdf\n",
      "found\n",
      "Ocado_Annual_Report_2020.pdf\n",
      "found\n",
      "XP_Power_Annual_Report_2020.pdf\n",
      "found\n",
      "Pirelli_Annual_Report_2020.pdf\n",
      "Kingfisher_Annual_Report_2020.pdf\n",
      "found\n",
      "Standard_Chartered_Annual_Report_2020.pdf\n",
      "found\n",
      "Just_Eat_Annual_Report_2020.pdf\n",
      "found\n",
      "Ferguson_Annual_Report_2020.pdf\n",
      "found\n",
      "Entain_Annual_Report_2020.pdf\n",
      "found\n",
      "HSBC_Holdings_Annual_Report_2020.pdf\n",
      "found\n",
      "EDF_Energy_Annual_Report_2020.pdf\n",
      "Croda_International_Annual_Report_2020.pdf\n",
      "found\n",
      "Morrisons_Annual_Report_2020.pdf\n",
      "found\n",
      "Royal_Dutch_Shell_Annual_Report_2020.pdf\n",
      "found\n",
      "Microsoft_Annual_Report_2020.pdf\n",
      "Smurfit_Kappa_Annual_Report_2020.pdf\n",
      "found\n",
      "British_American_Tobacco_Annual_Report_2020.pdf\n",
      "found\n",
      "ITV_Annual_Report_2020.pdf\n",
      "found\n",
      "Johnson_Matthey_Annual_Report_2020.pdf\n",
      "found\n",
      "Lloyds_Banking_Group_Annual_Report_2020.pdf\n",
      "found\n",
      "Shell_Annual_Report_2020.pdf\n",
      "found\n",
      "Premier_Foods_Annual_Report_2020.pdf\n",
      "found\n",
      "AstraZeneca_Annual_Report_2020.pdf\n",
      "found\n",
      "Spirax-Sarco_Annual_Report_2020.pdf\n",
      "found\n",
      "BP_Annual_Report_2020.pdf\n",
      "found\n",
      "CRH_Annual_Report_2020.pdf\n",
      "found\n",
      "Biogen_Annual_Report_2020.pdf\n",
      "Sainsburys_Annual_Report_2020.pdf\n",
      "found\n",
      "Rolls-Rocye_Annual_Report_2020.pdf\n",
      "found\n",
      "Barclays_Annual_Report_2020.pdf\n",
      "found\n",
      "United_Utilities_Annual_Report_2020.pdf\n",
      "found\n",
      "British_Land_Annual_Report_2020.pdf\n",
      "found\n",
      "Amazon_Annual_Report_2020.pdf\n",
      "DS_Smith_Annual_Report_2020.pdf\n",
      "found\n",
      "Rio_Tinto_Annual_Report_2020.pdf\n",
      "found\n",
      "Phoenix_Group_Holdings_Annual_Report_2020.pdf\n",
      "found\n",
      "Greggs_Annual_Report_2020.pdf\n",
      "found\n",
      "Avast_Annual_Report_2020.pdf\n",
      "found\n",
      "Alphabet_Annual_Report_2020.pdf\n",
      "Tesco_Annual_Report_2020.pdf\n",
      "found\n",
      "Severn_Trent_Annual_Report_2020.pdf\n",
      "found\n",
      "National_Grid_Annual_Report_2020.pdf\n",
      "found\n",
      "Mondi_Annual_Report_2020.pdf\n",
      "found\n",
      "JD_Sports_Annual_Report_2020.pdf\n",
      "found\n"
     ]
    }
   ],
   "source": [
    "# PhraseMatcher cases ought to be labelled. \n",
    "# The objective is to identify the page of occurance. \n",
    "\n",
    "# The hand labelled data contains the page at which information can be found\n",
    "# We therefore label all PhraseMatcher output on the correct page as 1 and \n",
    "# information on different pages as 0\n",
    "\n",
    "training_data['class'] = 0\n",
    "training_data['training'] = '' \n",
    "\n",
    "# Loop over manually labelled documents (125)\n",
    "for i in range(0,125):\n",
    "        target = labelled['report'][i]\n",
    "        print(target)\n",
    "        \n",
    "        # select all matches in one report\n",
    "        conditional = labelled.loc[labelled['report'] == target,'pay_ratio_present']\n",
    "        \n",
    "        # If the manually labelled set includes a pay-ratio score we continue\n",
    "        if int(labelled.loc[labelled['report'] == target,'pay_ratio_present']) == 1:\n",
    "            print('found')\n",
    "            \n",
    "            #Find page of occurance\n",
    "            page = labelled.loc[labelled['report'] == target,'pay_ratio_page_number_pdf']\n",
    "            # Set all matches from the PhraseMatcher that occur on the above page (in the same document)\n",
    "            # to class=1\n",
    "            training_data.loc[(training_data['File_name'] == target) & (training_data['page'] == int(page)),'class'] = 1\n",
    "            \n",
    "            #document to be included in training model\n",
    "            training_data.loc[(training_data['File_name'] == target),'training'] = 1\n",
    "            \n",
    "# training_data.to_csv(\"/home/jasper_h/Aug21_Pivigo_S/data/processed/training_pay_ratio_2020_new.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2fd3e7a",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367b857a",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d37f703b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "#edit directory\n",
    "sys.path.insert(0, '../scripts/')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn_classifier import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01dbe292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7464788732394366\n",
      "precision: 0.7444253859348199\n",
      "recall: 0.970917225950783\n",
      "F1 score: 0.8427184466019418\n",
      "Top ten features that predict 1 report vs 0: \n",
      "Class 1 best: \n",
      "(-9.71446307734805, ' 1,102,874')\n",
      "(-9.71446307734805, ' 1,102,874 cfo')\n",
      "(-9.71446307734805, ' feedback')\n",
      "(-9.71446307734805, ' feedback agm')\n",
      "(-9.71446307734805, ' gure ceo')\n",
      "(-9.71446307734805, ' methodology')\n",
      "(-9.71446307734805, ' methodology used')\n",
      "(-9.71446307734805, ' renumeration')\n",
      "(-9.71446307734805, ' renumeration policy')\n",
      "(-9.71446307734805, ' reporting')\n",
      "Class 2 best: \n",
      "(-3.587414802027043, 'pay')\n",
      "(-3.847522437722416, 'ratio')\n",
      "(-3.904629191222468, 'pay ratio')\n",
      "(-4.839509840835343, 'ceo')\n",
      "(-5.061272754593888, 'ceo pay')\n",
      "(-5.255482052313955, 'ceo pay ratio')\n",
      "(-5.514222662571994, 'percentile')\n",
      "(-5.534223751989595, 'ratios')\n",
      "(-5.59748498652079, 'pay ratios')\n",
      "(-5.689874647792486, 'executive')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasperhajonides/opt/anaconda3/envs/SocialNLP/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute coef_ was deprecated in version 0.24 and will be removed in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "\n",
    "# not all documents have been labelled and can be used for supervised learning \n",
    "training = training_data.loc[training_data['training']==1].reset_index()\n",
    "\n",
    "# Fit MultinomialNB classifier using stratified CV and obtain likelihoods for each phrase\n",
    "model, output = classify_NLP_df(training, ngram_range=(1, 3), alpha=0.25, classifier='MultinomialNB')\n",
    "training['likelihood'] = output['likelihood'][:,1]\n",
    "\n",
    "# Note: this model is tuned to identify the page, this is reflected in output metrics. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a838c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('../models/ceo_pay_ratio_model.pkl', 'wb') as fp:\n",
    "    pickle.dump(model, fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
